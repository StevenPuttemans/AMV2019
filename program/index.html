<!DOCTYPE html>
<html lang="en-us">

<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="description" content="Special session: Machine learning in Advanced Machine Vision for real-life and industrially relevant applications.">

<base href="https://stevenputtemans.github.io/AMV2019/">
<title>


     Program 

</title>
<link rel="canonical" href="https://stevenputtemans.github.io/AMV2019/program/">






<script type="text/javascript" src="/AMV2019/js/jquery-3.3.1.min.js"></script>


<link rel="stylesheet" href="/AMV2019/css/font-awesome.min.css">
<link rel="stylesheet" href="/AMV2019/css/nunito_sans.css">


    <link rel="stylesheet" href="/AMV2019/css/light-style.css">






<link rel="shortcut icon" href="/AMV2019/img/fav.ico">



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-120928140-3', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>





</head>


<body>
<div class="section" id="top">
    

    <div class="container hero  fade-in one ">
        
        <h1 class="bold-title is-1">Program</h1>
    </div>
    

    
    <div class="section  fade-in two ">
        <div class="container">
            
            <hr>
<nav class="nav nav-center">
    <span id="nav-toggle" class="nav-toggle"  onclick="document.getElementById('nav-menu').classList.toggle('is-active');">
      <span></span>
      <span></span>
      <span></span>
    </span>
    <div id="nav-menu" class="nav-left nav-menu">
      <span class="nav-item">
        <a href="/AMV2019/">Main</a>
      </span>
      <span class="nav-item">
        <a href="/AMV2019/about">About</a>
      </span>
      
      
      <span class="nav-item">
        <a href="/AMV2019/contact">Contact</a>
      </span>
    
      <span class="nav-item">
        <a href="https://stevenputtemans.github.io/AMV2019/index.xml"><i class="fa fa-rss"></i></a>
      </span>
    
    </div>
</nav>
<hr>

        </div>
        

        <div class="container markdown  fade-in two  top-pad">
            
            
            

<p>As a special session we will have 2 invited speakers that will talk about the challenges in advanced machine vision applications.</p>

<h2 id="invited-speaker">Invited speaker</h2>

<!--
### 1) Fatih Porikli

#### Transfer from academics towards industry and challenges

#### Biography

<div class="columns">
    <div style="padding: 40px 20px;">
      <img class="img-responsive avatar" src="img/profile_fpo.jpg" alt="My profile picture.">
    </div>
    <div class="column markdown" style="text-align: justify">
     Fatih Porikli has received his Ph.D. from New York University (NYU) in 2002. He is an IEEE Fellow and a Professor in the Research School of Engineering, Australian National University (ANU). He is also serving as the Technical Vice President at Futurewei Device & Hardware in San Diego. He led the Computer Vision Research Group Leader at NICTA, Australia and managed projects as the Distinguished Research Scientist at Mitsubishi Electric Research Laboratories, Cambridge. He developed satellite imaging solutions at HRL, Malibu CA, and 3D display systems at AT&T Research Laboratories, Middletown, NJ. His research interests include computer vision, deep learning, manifold learning, online learning, and image enhancement with commercial applications in smartphones, AR/VR, autonomous vehicles, video surveillance, defense, and medical systems. He received the R&D 100 Scientist of the Year Award in 2006, won six best paper awards at scientific events and recognized with six professional prizes at his industrial appointments. He authored more than 200 publications, co-edited two books, and invented 73 US patents. He has been an Associate Editor of several IEEE and Springer journals for the past 15 years.
    </div>
</div>

-->

<h3 id="ulas-bagci">Ulas Bagci</h3>

<h4 id="explainable-deep-learning-for-high-risk-ai-applications">Explainable Deep Learning for High Risk AI Applications</h4>

<h4 id="biography">Biography</h4>

<div class="columns">
    <div style="padding: 40px 20px;">
      <img class="img-responsive avatar" src="img/profile_uba.png" alt="My profile picture.">
    </div>
    <div class="column markdown" style="text-align: justify">
    Dr. Bagci is a faculty member at the Center for Research in Computer Vision (CRCV), and the Assistant Professor in University of Central Florida (UCF). His research interests are artificial intelligence, machine learning and their applications in biomedical and clinical imaging. Previously, he was a staff scientist at the NIH's Center for Infectious Disease Imaging (CIDI) Lab, department of Radiology and Imaging Sciences (RAD&IS).  Dr. Bagci had also been the leading scientist (image analyst) in biosafety/bioterrorism project initiated jointly by NIAID and IRF. Dr. Bagci obtained his PhD degree from School of Computer Science, University of Nottingham (UK) in collaboration with Radiology department of University of Pennsylvania (with Prof. Udupa, MIPG). He is senior member of IEEE and RSNA, and member of scientific organizations such as Society of Nuclear Medicine and Molecular Imaging (SNMMI), American Statistical Association (ASA), Royal Statistical Society (RSS), AAAS, and MICCAI. He has served as a program committee member for various conferences, and a regular reviewer for many prestigious journals in his fields and received best paper and best reviewer awards. Dr. Bagci is the recipient of many awards including NIH's FARE award (twice), RSNA Merit Certificates (5+ times), best paper awards, poster prizes, and several highlights in journal covers, media, and news.
    </div>
</div>

<h2 id="tentative-program">Tentative program</h2>

<p>Oral presentation = 10 min presentation + 2 min Q&amp;A</p>

<table>
<thead>
<tr>
<th align="left">Time</th>
<th align="left">What</th>
<th align="left">Who</th>
<th align="left">Title</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">3:15PM</td>
<td align="left">Welcome</td>
<td align="left">Steven Puttemans</td>
<td align="left">- - -</td>
</tr>

<tr>
<td align="left">3:20PM</td>
<td align="left">Invited speaker</td>
<td align="left">Ulas Bagci</td>
<td align="left"><a href="presentations/Bagci.pdf" target="_blank">Explainable Deep Learning for High Risk AI Applications</a></td>
</tr>

<tr>
<td align="left">3:55PM</td>
<td align="left">Oral 1</td>
<td align="left">Muhammad Hamdan</td>
<td align="left"><a href="presentations/muhammad_hamdan.pdf" target="_blank">Mass Estimation from Images using Deep Neural Network and Sparse Ground Truth</a></td>
</tr>

<tr>
<td align="left">4:07PM</td>
<td align="left">Oral 2</td>
<td align="left">Timothy Callemein</td>
<td align="left"><a href="presentations/timothy_callemein.pdf" target="_blank">Anyone Here? Smart Embedded Low-Resolution Omnidirectional Video Sensor to Measure Room Occupancy</a></td>
</tr>

<tr>
<td align="left">4:19PM</td>
<td align="left">Oral 3</td>
<td align="left">Ning Jia</td>
<td align="left"><a href="presentations/ning_jia.pdf" target="_blank">Coarse Annotation Refinement for Segmentation of Dot-Matrix Batchcodes</a></td>
</tr>

<tr>
<td align="left">4:31PM</td>
<td align="left">Oral 4</td>
<td align="left">Benjamin Lutz</td>
<td align="left"><a href="presentations/benjamin_lutz.pdf" target="_blank">Evaluation of Deep Learning for Semantic Image Segmentation in Tool Condition Monitoring</a></td>
</tr>

<tr>
<td align="left">4:43PM</td>
<td align="left">Oral 5</td>
<td align="left">Ji Ling</td>
<td align="left"><a href="https://www.dropbox.com/home/File%20requests/Orals%20AMV2019?preview=presentation_ji_ling.mov" target="_blank">Infrared and Visible Image Fusion via Multi-Discriminators Wasserstein Generative Adversarial Network</a></td>
</tr>

<tr>
<td align="left">4:55PM</td>
<td align="left">Oral 6</td>
<td align="left">Dries Hulens</td>
<td align="left"><a href="presentations/dries_hulens.pdf" target="_blank">Deep Diamond Re-ID</a></td>
</tr>

<tr>
<td align="left">5:07PM</td>
<td align="left">Oral 7</td>
<td align="left">Rodrigo Leonardo &amp; Amber Hu</td>
<td align="left">Fusing Visual and Textual Information to Determine Content Safety</td>
</tr>

<tr>
<td align="left">5:19PM</td>
<td align="left">Best Paper Award + Closing remarks</td>
<td align="left">Steven Puttemans</td>
<td align="left">- - -</td>
</tr>

<tr>
<td align="left">5:30PM</td>
<td align="left">End of special session</td>
<td align="left">- - -</td>
<td align="left">- - -</td>
</tr>
</tbody>
</table>

        </div>
        

        <div class="disqus">
            
        </div>

        <div class="container has-text-centered top-pad">
            <hr>
            <a href="#top">
                <i class="fa fa-arrow-up"></i>
            </a>
            <hr>
        </div>

        <div class="section" id="footer">
    <div class="container has-text-centered">
    
        AMV2019 special session website made with the <a href="https://themes.gohugo.io/hugo-theme-introduction/">Introduction</a> theme for <a href="https://gohugo.io/">Hugo</a>.
    
    </div>
</div>

    </div>
    
</div>



<script>
    $('a[href^="https:\/\/stevenputtemans.github.io\/AMV2019\/program\/#"]').click(function (e) {
        e.preventDefault();
        var target = this.hash;
        $('html, body').animate({
            scrollTop: $(target).offset().top
        }, 500);
        return false;
    })
</script>

</body>
